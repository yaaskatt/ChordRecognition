from sklearn.model_selection import train_test_split
from keras.layers import Dense, Input, Conv2D, Flatten, Dropout, Lambda, Reshape
from keras.models import Model, Sequential
from keras import backend as K
import numpy as np
from keras.optimizers import RMSprop, Adam
from imblearn.over_sampling import SMOTE
from processing.paths import Path
from processing import datawork
from sklearn.model_selection import KFold


def autoenc(input_shape):
    # Вход
    x = Input(name='inputs', shape=input_shape, dtype='float32')
    flat_x = Flatten()(x)
    # Кодировщик
    enc = Dense(input_shape[0], activation='relu', name='encoder')(flat_x)
    # Декодер
    dec = Dense(input_shape[0] * input_shape[1], activation='sigmoid', name='decoder')(enc)
    dec = Reshape((input_shape[0], input_shape[1], input_shape[2]))(dec)
    Model(inputs=x, outputs=dec).summary()
    return Model(inputs=x, outputs=dec)

def train_denoiser_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

    model = autoenc(input_shape)
    model.compile(optimizer="adadelta", loss="binary_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=20,
              batch_size=2056,
              shuffle=True, validation_data=(x_test, y_test))
    model.save(Path.denoiser)


def train_frame_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)

    model = Sequential()
    model.add(Conv2D(48, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.1))
    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.1))
    model.add(Dense(y.shape[1], activation='softmax'))

    model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=130,
              batch_size=1000,
              validation_data=(x_test, y_test))
    model.save(Path.frameClassifier)


def train_chord_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

    model = Sequential()
    model.add(Conv2D(48, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.1))
    model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))
    model.add(Dropout(0.1))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.1))
    model.add(Dense(y.shape[1], activation='softmax'))

    adam = Adam(learning_rate=0.0001)
    model.compile(optimizer=adam, loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=500,
              batch_size=200,
              validation_data=(x_test, y_test))
    model.save(Path.chordClassifier)


def train_beat_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

    model = Sequential()
    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.2))
    model.add(Conv2D(48, kernel_size=3, activation='relu', padding='same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.2))
    model.add(Dense(y.shape[1], activation='softmax'))

    adam = Adam(learning_rate=0.0001)
    model.compile(optimizer=adam, loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=1000,
              batch_size=2000,
              validation_data=(x_test, y_test))
    model.save(Path.beatClassifier)

def create_base_network(input_shape):
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(256, activation="relu")(x)
    x = Dropout(0.4)(x)
    x = Dense(128, activation="relu")(x)
    x = Dropout(0.4)(x)
    x = Dense(512, activation="softmax")(x)
    return Model(input, x)

def euclidean_distance(vects):
    x, y = vects
    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))


def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return (shape1[0], 1)

def contrastive_loss(y_true, y_pred):
    margin = 1
    square_pred = K.square(y_pred)
    margin_square = K.square(K.maximum(margin - y_pred, 0))
    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)

def accuracy(y_true, y_pred):
    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))

def train_grouper_model(x1, x2, y):
    input_shape = (x1.shape[1:])

    x = np.concatenate((x1.reshape(x1.shape[0], x1.shape[1] * x1.shape[2]),
                        x2.reshape(x2.shape[0], x2.shape[1] * x2.shape[2])), axis=1)

    oversample = SMOTE()

    scores = []

    for train_index, test_index in KFold(10).split(x):

        x_train, y_train = x[train_index], y[train_index]
        x_test, y_test = x[test_index], y[test_index]

        x_train, y_train = oversample.fit_resample(x_train, y_train)
        x_test, y_test = oversample.fit_resample(x_test, y_test)

        x_train = x_train.reshape(x_train.shape[0], x1.shape[1]*2, x1.shape[2])
        x_test = x_test.reshape(x_test.shape[0], x1.shape[1]*2, x1.shape[2])

        x1_train, x2_train = np.split(x_train, 2, axis=1)
        x1_test, x2_test = np.split(x_test, 2, axis=1)

        base_network = create_base_network(input_shape)
        input1 = Input(shape=input_shape)
        input2 = Input(shape=input_shape)
        processed1 = base_network(input1)
        processed2 = base_network(input2)

        distance = Lambda(euclidean_distance,
                          output_shape=eucl_dist_output_shape)([processed1, processed2])

        model = None
        model = Model([input1, input2], distance)

        rms = RMSprop()
        model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])
        model.fit([x1_train, x2_train], y_train,
                  batch_size=500,
                  epochs=100,
                  validation_data=([x1_test, x2_test], y_test))
        scores.append(model.evaluate([x1_test, x2_test], y_test)[1])
    print("Total score:", np.mean(scores))
    model.save(Path.grouper)



from sklearn.model_selection import train_test_split
from keras.layers import Dense, Input, Conv1D, Conv2D, Flatten, Dropout, Lambda, Reshape, MaxPooling1D
from keras.models import Model, Sequential
from keras import backend as K
import numpy as np
from keras.optimizers import RMSprop, Adam
from imblearn.over_sampling import SMOTE
from processing.paths import Path
from processing import datawork
from sklearn.model_selection import KFold


def autoenc(input_shape):
    # Вход
    x = Input(name='inputs', shape=input_shape, dtype='float32')
    flat_x = Flatten()(x)
    # Кодировщик
    enc = Dense(input_shape[0], activation='relu', name='encoder')(flat_x)
    # Декодер
    dec = Dense(input_shape[0] * input_shape[1], activation='sigmoid', name='decoder')(enc)
    dec = Reshape((input_shape[0], input_shape[1], input_shape[2]))(dec)
    Model(inputs=x, outputs=dec).summary()
    return Model(inputs=x, outputs=dec)

def train_denoiser_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

    model = autoenc(input_shape)
    model.compile(optimizer="adadelta", loss="binary_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=20,
              batch_size=2056,
              shuffle=True, validation_data=(x_test, y_test))
    model.save(Path.denoiser)


def train_frame_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)

    model = Sequential()
    model.add(Conv2D(48, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.1))
    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.1))
    model.add(Dense(y.shape[1], activation='softmax'))

    model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=130,
              batch_size=1000,
              validation_data=(x_test, y_test))
    model.save(Path.frameClassifier)


def train_chord_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

    model = Sequential()
    model.add(Conv2D(48, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.1))
    model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))
    model.add(Dropout(0.1))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.1))
    model.add(Dense(y.shape[1], activation='softmax'))

    adam = Adam(learning_rate=0.0001)
    model.compile(optimizer=adam, loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=500,
              batch_size=200,
              validation_data=(x_test, y_test))
    model.save(Path.chordClassifier)


def train_beat_classifier_model(x, y):
    x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
    input_shape = (x.shape[1:])
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

    model = Sequential()
    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))
    model.add(Dropout(0.2))
    model.add(Conv2D(48, kernel_size=3, activation='relu', padding='same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(1024, activation="relu"))
    model.add(Dropout(0.2))
    model.add(Dense(y.shape[1], activation='softmax'))

    adam = Adam(learning_rate=0.0001)
    model.compile(optimizer=adam, loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit(x_train, y_train,
              epochs=1000,
              batch_size=2000,
              validation_data=(x_test, y_test))
    model.save(Path.beatClassifier)

def create_base_network(input_shape):
    input = Input(shape=input_shape)
    x = Conv1D(64, 10, activation='relu', input_shape=input_shape, padding='same')(input)
    x = MaxPooling1D()(x)
    x = Conv1D(128, 7, activation='relu', padding='same')(x)
    x = Dropout(0.4)(x)
    x = MaxPooling1D()(x)
    x = Conv1D(128, 4, activation='relu', padding='same')(x)
    x = Dropout(0.4)(x)
    x = MaxPooling1D()(x)
    x = Conv1D(256, 4, activation='relu', padding='same')(x)
    x = Flatten()(x)
    x = Dense(4096, activation='sigmoid')(x)
    return Model(input, x)

def euclidean_distance(vects):
    x, y = vects
    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))


def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return (shape1[0], 1)

def contrastive_loss(y_true, y_pred):
    margin = 1
    square_pred = K.square(y_pred)
    margin_square = K.square(K.maximum(margin - y_pred, 0))
    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)

def accuracy(y_true, y_pred):
    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))

def train_grouper_model(x1, x2, y):
    input_shape = (x1.shape[1:])

    x = np.concatenate((x1.reshape(x1.shape[0], x1.shape[1] * x1.shape[2]),
                        x2.reshape(x2.shape[0], x2.shape[1] * x2.shape[2])), axis=1)

    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

    oversample = SMOTE()


    x_train, y_train = oversample.fit_resample(x_train, y_train)
    x_test, y_test = oversample.fit_resample(x_test, y_test)

    x_train = x_train.reshape(x_train.shape[0], x1.shape[1]*2, x1.shape[2])
    x_test = x_test.reshape(x_test.shape[0], x1.shape[1]*2, x1.shape[2])

    x1_train, x2_train = np.split(x_train, 2, axis=1)
    x1_test, x2_test = np.split(x_test, 2, axis=1)

    base_network = create_base_network(input_shape)
    input1 = Input(shape=input_shape)
    input2 = Input(shape=input_shape)
    processed1 = base_network(input1)
    processed2 = base_network(input2)

    distance = Lambda(euclidean_distance,
                      output_shape=eucl_dist_output_shape)([processed1, processed2])

    model = Model([input1, input2], distance)

    rms = RMSprop()
    model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])
    model.fit([x1_train, x2_train], y_train,
              batch_size=50,
              epochs=100,
              validation_data=([x1_test, x2_test], y_test))
    model.save(Path.grouper)

input_shape = (x1.shape[1:])

    x1_oversample, x2_oversample = [], []
    for i in range(len(x2)):
        if y[i] == 0:
            k = i - 1
            while y[k-1] == 1 and y[k] == 1:
                x1_oversample.append(x1[k])
                x2_oversample.append(x2[i])
                k -= 1
    x1 = np.concatenate((x1, np.array(x1_oversample)))
    x2 = np.concatenate((x2, np.array(x2_oversample)))
    y = np.concatenate((y, np.zeros(len(x1_oversample))))

    print("num of \'1\':", sum(num == 1 for num in y), "num of \'0\':", sum(num == 0 for num in y))

    x1_train, x1_test, x2_train, x2_test, y_train, y_test = train_test_split(x1, x2, y, test_size=0.2)

    base_network = create_base_network(input_shape)
    input1 = Input(shape=input_shape)
    input2 = Input(shape=input_shape)
    processed1 = base_network(input1)
    processed2 = base_network(input2)

    distance = Lambda(euclidean_distance,
                      output_shape=eucl_dist_output_shape)([processed1, processed2])

    model = Model([input1, input2], distance)

    rms = RMSprop()
    model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])
    model.fit([x1_train, x2_train], y_train,
              batch_size=25,
              epochs=100,
              validation_data=([x1_test, x2_test], y_test))
    model.save(Path.grouper)
























































































